---
layout : post
title : "DESC"
date : 2021-04-30 +0900
description : Semantic Consistency를 응용하여 depth estimation에 domain adaptation을 적용한 DESC 논문의 간단한 리뷰입니다.
tag : [PaperReview]
---

### DESC: Domain Adaptation for Depth Estimation vai Semantic Consistency, BMVC 2020



### Abstract

 정확한 실제 depth annotation을 얻는 것은 어려운 일이다. self-supervised method가 이러한 문제를 video/stereo sequence 등으로 해결하려고 하였으나, 항상 가능한 것은 아니었다.(domain adaptation을 말하는 듯 하다) 대신에, 이번 논문에서 우리는 monocular depth estimation을 domain adaptation으로 해결한 모델을 보여준다. 우리는 domain 사이의 gap을 fully-annotated source dataset과 non-annotated target dataset을 이용해서 줄여보았다. main model과 second model 사이의 consistency를 semantic segmentation과 edge map을 이용해서 실험해보았고, instance height에 대해 소개한다. 이러한 방법은 monocular depth estimation의 standard domain adaptation benchmark에서 평가된다.



### Introduction

 monocular depth estimation에서 정확한 depth map을 뽑는 것은 꽤나 많은 양의 annotation dataset이 필요하다. 그래서 LiDAR와 같은 것들을 추가적으로 사용하기도 한다. 하지만 이러한 방법은 매우 time-consuming이다. 이를 해결하기 위해 self-supervision의 방법들이 나왔다. 하지만 여전히 stereo와 같은 dataset들은 항상 이용가능한 dataset은 아니다. 그래서 synthetic dataset들이 나왔는데, 이들은 정말 많은 dataset을 제공한다. 하지만, 이를 실제에 적용시키기 위해서는 domain adaptation이 필요하다. 이를 위해 domain adaptation technique이 필요해짐을 사람들이 느꼈고, source dataset $S$ 와 target dataset $T$ 를 연결할 수 있도록 최근 연구 중이다.

 최근 연구에서는 semantic segmentation과 instance detection이 학습동안 depth information을 소개하는 것으로 gap을 줄여준다는 논문이 몇몇 나왔다. 이는 아래 그림을 참조하되, 자세한 것은 논문을 확인하자. 그림만 봐도 잘 알 수 있긴 하다.

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-1.PNG)

Chen, Yuhua, et al. "Learning semantic segmentation from synthetic data: A geometrically guided input-output adaptation approach." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2019.

![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-2.PNG)

Liu, Keng-Chi, et al. "What synthesis is missing: Depth adaptation integrated with weak supervision for indoor scene parsing." *Proceedings of the IEEE/CVF International Conference on Computer Vision*. 2019.

 이러한 발견들로 인해 panoptic segmentation model을 이용해서 domain의 gap을 줄이고 monocular depth estimation의 성능을 향상시킬 수 있도록 하는 것을 발견한다.

 Domain adaptation은 pseudo-labelling과 source/target domain에서의 에측의 consistency에서 헤택을 받게 되므로, 우리는 semantic annotation을 이용하여 두 domain 사이의 depth estimation의 consistency를 강요한다. 아래 그림은 우리 task의 overview를 보여준다.

![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-3.PNG)

 여하튼 contribution을 정리하면 다음과 같다.

- object size를 이용한 target domain에서 depth pseudo-label을 형성하는 것을 제안
- high-level semantic과 low-level edge map을 이용해 학습한 2nd model을 이용한 consistency constraint
- VirtualKITTI에서 KITTI로의 SOTA



### Related Work

__2.1. Monocular Depth Estimation__

__Self-Supervision__

__Depth and Semantic Information__

__2.2. Domain Adaptation__

__Depth Estimation.__



### Method

 우리의 domain adaptation인 Depth Estimation via Semantic Consistency (DESC) 접근을 제안한다. 이에 대한 overview는 아래 그림에 나와있다.

![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-4.PNG)

__3.1. Pseudo-labelling using Instance Height__

 Struct2Depth에서는 video self-supervision에서 움직이는 object를 다루기 위해 instance height를 사용했다. 그래서, Struct2Depth에서는 아래와 같은 식을 풀어서 임의의 distance를 구한다.

![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-5.PNG)

 위 식에서 $\hat{D}$ 는 approximate distance to the object를, $f$ 는 focal length를, $H$ 는 predicted instance size를, $h$ 는 물체의 physical height(실제 세상에서의 높이)를 의미한다. Struct2Depth에서는 object의 size를 car을 기준으로 잡았다. 즉, car class로 detect되는 instance들은 same height를 가지고 있다고 가정하고, 이는 bbox를 이용하여 잡게 되었을 때, 그 높이에 따라 depth가 결정된다. 그런데 우리는 이것 말고, class보다는 object instance마다 $h$ 를 설정해두는 것이 더 좋다고 생각했다. Struct2Depth에서는 unsupervised 방법으로 $h$ 를 학습한 반면, 우리는 source domain data에서 이를 학습시킬 수 있다. 그래서 우리는 이에 대한 network을 $G_h$ 로 사용했다. 우리는 $G_h$ 가 source data의 label을 사용해서 $h_{GT,i}$ 를 예측하도록 했다.(여기서 $i$ 는 instance를 의미) 즉, $h_{GT,i}=\frac{H_i \cdot \hat{D}_{S,i}}{f_S}$ 가 된다. 참고로 $\hat{D}_{S,i}$ 는 depth GT에서 바로 오는 것이다. 이를 얻기 위해, 우리는 $\hat{D}_i=median(M_{S,i}\bigodot y_S)$ 을 이용하는데, $M_{S,i}$ 는 binary segmentation instance mask이고, $\bigodot$ 은 hadamard product(그냥 elemental wise product), $y_S$ 는 GT depth를, median operation은 위 과정이 오로지 non-zero value에 의해서만 수행이 된단 뜻이다. 따라서, $G_h$ 는 

![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-6.PNG)

 위 식으로 source domain에서 train된다. 여기서 $n_I$ 는 detected instance를 의미한다. target domain으로 넘어가서는, depth-pseudo-label $\hat{D}_{T,i}$  를 계산하는데, 이는 위에 소개된 depth를 구하는 곳으로 들어가게 되고, 아래와 같은 방법을 통해 loss가 계산이 된다.

![img7](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-7.PNG)

 위 식에서 $p_I$ 는 모든 binary segmentation mask $M_{T,i}$ 의 non-zero pixel의 합을 의미하고, $x_T$ 는 target domain에서의 image를, $\phi$ 는 learnable scalar를 의미한다. 이 learnable scalar는 source domain과 target domain 사이에서 camera로 인한 mismatch를 보정해주는 역할을 수행한다. 우리는 semantic annotation을 추출하기 위해 external data에서 train된 panoptic segmentation model을 사용해서, target domain에는 존재하는데 source domain에는 없는 사람 같은 것들이 detect가 된다. 이러한 class들을 위해, 우리는 instance-based height를 학습시킨 것이다.

__3.2. Consistency of Predictions using Semantic Information__

 많은 work들이 domain adaptation에서 domain에 따른 performance gap을 줄이는 것에 consistency가 필요하다는 것을 보여왔다. semi-supervised learning에서도 비슷한 observation이 있다. 이러한 발견을 삼아, 우리는 main depth estimation network인 $G_D$ 와 secondary network인 $G_S$ 사이의 consistency를 강요했다. 바로 semantic segmentation map과 edge map이다.

__Semantic Structure__

 semantic segmentation map은 scene의 high-level structure 정보를 건네주고, 이는 depth structure를 에측하는데에 도움을 준다. (어떻게요?) 아무튼 one-hot encoding보다는 semantic class label에 상응하는 정수 형태로 정보를 주면 된다고 한다.

__Edge Map__

 edge map을 texture로 사용했고, network에 다른 modality로 주었다. 아무튼 이러한 것들이 조금 도움이 되었다고 한다.

__Consistency__

 $G_D$ 와 $G_S$ 가 서로 다른 modality의 input을 받기 때문에, 두 domain 사이의 consistency를 강요하는 것은 성능 향상에 도움이 된다. 우리는 이를 다음과 같이 정했다.

![img8](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-8.PNG)

 위 식에서 Con은 consistency를 의미한다.

__3.3. Training Loss__

__Depth Estimation Loss.__

 $G_D$ 의 경우 source domain과의 depth estimation과 supervised로 학습된다.(pixel-wise multiscale L1 loss)

__Image Translation__

 T2Net을 이용해서 $G_{S->T}$ translate을 진행한다.(cycle consistency 없이). T2Net은 $x_{S->T}$ 가 $x_T$ 와 유사한 distribution을 가지도록 하기 위해 least-square adversarial term인 $L_{GAN}$ 을 쓰고, source domain에서의 image와 $x_{s->T}$ 사이가 consistent하도록 $L_D$ 를 constraint로 이용한다. 또한 L1 identity loss $L_{IDT}$ 를 추가하는데, 이는 source to domain에서 identity mapping을 할 수 있도록 하게 만드는 요소이다.

__Smoothing.__

 우리는 Monodepth에서 소개된 smoothing term인 $L_{Sm}$ 을 이용해서 성공적으로 domain adaptation에 적용할 수 있었다.

__Overall Loss__

 위를 몽땅 합치는데, 앞의 $\lambda$ 들은 전부 hyperparamter이다.

![img9](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-9.PNG)



### Experiment

 semantic annotation은 COCO-stuff에서 학습된 ResNet-101 panoptic segmentation을 detectron2 library에서 썼고, $G_{S->T}$ 로는 ResNet based model을, $G_D$ 와 $G_S$ 는 U-Net을 사용했다. image translation과 depth estimation architecture는 각각 GASDA, T2Net을 썼다. 이외 각종 hyperparameter들에 대한 설명이 나온다.

__Virtual KITTI -> KITTI__

__Cityscapes->KITTI__

__Evaluation in KITTI__

__4.1. Quantitative Results__

__Comparison with State-of-the-Art__

![img10](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-10.PNG)

__Ablation Study__

![img11](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-11.PNG)

__Stereo Supervision__

![img12](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-12.PNG)

__Evaluation on KITTI Stereo.__

![img13](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-13.PNG)

__Cityscapes->>KITTI__

![img14](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-14.PNG)

__4.2. Qualitative Results__

![img15](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210430-15.PNG)



### Conclusion



### Reference

Lopez-Rodriguez, Adrian, and Krystian Mikolajczyk. "DESC: Domain Adaptation for Depth Estimation via Semantic Consistency." *arXiv preprint arXiv:2009.01579* (2020).

