---
layout : post
title : "CycleISP"
date : 2021-04-06 +0900
description : 사진의 Noise를 없애는 과정인 Denoizing을 새롭게 분석하여 SOTA를 달성한 CycleISP 논문의 간단한 리뷰입니다.
tag : [PaperReview]
---

### CycleISP: Real Image Restoration via Improved Data Synthesis, CVPR 2020



### Abstract

 Camera denoising에서 실제 dataset을 다루는 것은 엄청 비싸고 복잡한 과정이다. 그래서 현재 존재하는 많은 denoising network들은 사진에 AGWN(Additive white Gaussian Noise)를 추가한 다음 이를 없애는 방향으로 학습시키게 되는데, 이렇게 만들어진 network들은 synthetic dataset에는 효과적이더라도 real image의 noise를 없애는 것엔 효과적이지 못했다.

 그래서, 저자는 AWGN을 적용하는 것이 올바른 방법이 아니라는 것을 보여주며, RGB image와 RAW image 사이를 서로 변경하는 network을 제안하고, RAW image에서 noise를 추가한 다음 RGB image로 변경하여 noise RGB image를 만들어서 real noisy image를 제작하는 network를 만들게 된다. 이렇게 진행하는 이유는, noise가 만들어지는 요소가 여러가지가 있는데, sensor에서 image를 받고 변환하는 과정 중에 생기는 noise가 진짜 noise라고 생각하게 되어 이러한 방식으로 network을 설계하게 되었다. 이렇게 만들어진 network를 CycleISP라고 한다.

 이후 비슷한 구조로 denoising network을 만들어 CycleISP에서 만들어진 synthetic image로 학습시킨 결과, SOTA를 달성했다고 한다. 이 때 다른 모델들에 비해 5배나 작은 parameter를 가지고 있다고 한다.

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-1.PNG)

 자세히 보면, 각 Network들이 약간의 noise를 여전히 가지고 있다는 것을 확인할 수 있다.(red dot) 하지만 CycleISP의 결과물로 학습된 저자가 제안한 denoising network의 결과물에서는 해당하는 점을 찾기 힘들다.(즉, 성능이 좋다)



### Introduction

 CNN이 성공한 가장 큰 이유는 거대한 dataset이 생겼기 때문이다. 하지만, 이러한 것들에도 불구하고 low-level vision task에는 아직도 어려움이 따른다.(그만큼 dataset이 아직 없기 때문에) 예를 들어, 어떤 사진을 서로 다른 camera로 찍게 된다면 그 noise는 모두 달라지게 되고,(hardware 특성 때문에) 그 noise가 서로 다르기에 이를 dataset 만으로 표현하기에는 그 경우의 수가 너무 많고, 아직도 필요한 dataset이 많다. 최근 denoising에 있어서 work들은 AWGN을 임의의 사진에 적용시킨 다음, noise 사진에 이를 적용하여 denoising된 image를 뽑아내는 task를 수행해왔다.

 하지만 이러한 방법들로 만들어진 network들은 real image dataset에 적용되기는 힘들었다. "real" noise는 "AWGN"이 아니기 때문이다. 그래서 우리는 RAW와 RGB image 모두에서 realistic noisy image를 만들 수 있는 방법을 생각했다. Sensor에서 받은 RAW image data는 ISP(Image signal processing)을 통해 RGB image로 변환이 되어 컴퓨터에 저장이 되는데, 저자의 생각엔 이러한 process라면 RAW image data에서 noise를 추가한 다음 RGB image로 변환해야 현실적인 noise를 얻을 수 있다고 생각했다. 따라서, 이는 uniform한 error를 만드는 AWGN보다는 synthesize realistic noise에 더 가까운 noise를 만들어내게 된다.

 traditional한 방법들의 문제는, 같은 장소를 다른 camera로 찍었을 때 이러한 camera에 대한 특성을 모두 알고 있어야 하는데, 이러한 것을 고려하지 않는다면 generalizability에 대한 결여가 생기게 된다. 그래서 이를 우리는 neural network으로 접근하게 되었다.

 따라서 우리의 contribution은 다음과 같다.

- device-agnostic(장비가 뭐던 간에 상관없이) transformation을 배워 RGB, RAW image 사이의 변환을 수행하는 CycleISP
- Real image noise synthesizer
- Dual attention mechanism을 이용한 denoising 및 synthesizing realistic noise
- DND와 SIDD dataset에서 SOTA를 달성 with about 5 times less parameter
- Stereoscopic cinema에서의 color matching에 응용 가능



### Related Work

 image에서 noise를 없애는 classic한 method로는 DCT, wavelet 등을 이용하여 transform coefficient를 조정하고, neighborhood value를 평균하는 등의 방법을 사용해왔다. 하지만 이러한 방법들은 모두 한계가 있었다.

 그래서 최근에는 neural network을 이용해서 접근하는 움직임이 많았다. 그 중에서 우리는 RAW image뿐 아니라 RGB image에서도 noise를 제거하는 CycleISP를 제안한다.



### CycleISP

 첫번째로, 우리는 RAW->RGB의 과정인 ISP와, 그 역과정인 reverse ISP를 모두 가능하게 하는 network라는 의미에서 CycleISP라는 이름을 지었다. 아래 그림은 network의 overview이다.

![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-2.PNG)

 위 그림을 자세히 살펴보자.

__3.1. RGB2RAW Network Branch__

 RGB2RAW network의 목적은 camera ISP를 invert하는 것이다. neural network의 특성 상, RGB2RAW branch는 그 어떤 camera parameter도 필요로 하지 않는다. 처음 convolutional layer를 지나고 난 이후, 일련의 RRG를 통과하고, 다시 convolutional layer를 지나게 된다. 이렇게 나온 마지막 결과물은 Mosaic를 통해 RAW image로 최종적으로 들어가게 된다. 이 때의 효과로는, tone mapping, gamma correction, color correction, white balance, 다른 transformation 등 radiance(빛)과 연관된 항목들을 없애는 역할을 하게 된다고 한다. mosaic의 경우 bayer sampling function을 사용한다. 

![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-3.PNG)

 결과적으로 얻게 되는 network의 loss는 위와 같다.

__3.2. RAW2RGB Network Branch__

 RAW2RGB는 synthetic realistic noise data를 만들기 위해 존재하는 network이다.(ISP 역할) 위 network overview에서 noise injection module이 있는데, training할 당시에는 __OFF__ 로 둔다. RGB2RAW와 마찬가지로, convolutional layer를 통과하는데, RRG의 마지막 block에 도달하기 전 color correction이라는 것을 수행한다. 그리고 이후 다시 RRG block 1개와 convolutional network을 지난 후 pixel shuffle을 지나 RGB image로 복원이 된다.

__Color attention unit__

 우리가 train하면서 사용한게 MIT-Adobe FiveK dataset인데, 여기서 너무 다양한 camera를 쓰고 있어서 다양하고 complex한 ISP에도 적응이 되도록 해야 했다. 그래서 우리는 RAW에서 RGB로 복원하는 과정에 color attention을 추가하여 조금 더 원활한 복원이 이루어지도록 만들었다.

![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-4.PNG)

 구조는 위와 같다. K는 gaussian kernel을 의미하는데, standard deviation 은 12로 설정이 되어있다. 이렇게 나온 결과물은 아래와 같은 식을 통해 RAW2RGB에서 output으로 나가게 된다.

![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-5.PNG)

 여기서 loss는 아래와 같이 간단한 l1 loss로 구하게 된다.

![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-6.PNG)

__3.3. RRG: Recursive Residual Group__

 여태껏 나왔던 RRG Block이란 것에 대한 설명이다. 구조는 아래와 같다.

![img8](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-8.PNG)

 RRG는 일련의 DAB(Dual Attention Block)으로 구성이 되어있고, 마지막엔 3x3 Conv layer를 지나게 된다. 그리고 residual skip connection을 통과하게 된다.

 dual residual block은 위 그림에서 위쪽에 위치한 것과 같이, Spatial Attention과 Channel Attention으로 나누어져있다. 이러한 결과를 concat해서 1x1 Conv layer를 지나고, input을 skip connection하여 더한 후 output으로 내뱉게 된다. 이를 식으로 나타낸 결과는 아래와 같다.

![img7](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-7.PNG)

 위 식에서 CA는 Channel Attention이고, SA는 Spatial Attention이다.

__Channel Attention__

 위 그림 참조.

__Spatial Attention__

 위 그림 참조.

__3.4 Joint Fine-tuning of CycleISP__

 CycleISP는 training 과정이 조금 독특한 편인데, 일단 RGB2RAW와 RAW2RGB를 각각 훈련시킨 다음, 이후 한꺼번에 학습을 시켜서 최종적으로 CycleISP를 만들게 된다. 특이한 것으로는 두 network의 loss backward가 조금 다르다. 자세한건 코드 참조.(RAW2RGB는 오로지 RAW2RGB의 loss.backward만 받는 받면, RGB2RAW의 경우는 두 network 모두에서 data를 받게 된다.)

![img9](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-9.PNG)

![img10](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-10.PNG)



### Synthetic Realistic Noise Data Generation

 realistic noise data를 만드는 것은 다음과 같다.

__Data for RAW denoising__

 clean한 RGB image를 집어넣어서, clean RAW image와 noisy RAW image를 만들어내는 과정이다. clean RAW image는 RGB2RAW network의 output을 그대로 사용하는 것이고, noisy RAW의 경우는 sampling shot/read noise factor의 방법을 이용하여 추가하게 된다.(Noise injection module을 이용함. 이 때 추가하는 noise는 heteroscedastic gaussian으로, variance가 변하는 gaussian random variable이라고 보면 될 것 같다.) 

__Data for sRGB denoising__

 RGB2RAW network을 통과하고 나온 clean RAW image와 noisy RAW image 두 개에 Pack RAW라는 것을 통과시켜 RGGB로 만든 후, RAW2RGB network을 통과시켜서 clean RGB image와 noisy RGB image를 만들게 된다. 이렇게 만들어진 data들을 이용하여 deonising network을 학습시키게 된다.



### Denoising Architecture

 여태까지는 dataset을 synthesize하는 방법에 대해 알아왔다면, 이를 dataset으로 하여 학습시킬 모델을 여기서 가르쳐준다.(따지고보면 self-training 기법에 좀 가깝긴 하다.)

 network는 단순하다. RRG block들과 conv layer, skip connection만 존재한다.

![img11](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-11.PNG)

 RGB denoising이냐 RAW denoising이냐에 따라 다른데, RAW denoising의 경우에는 4 channel의 noisy packed image와 4 channel의 noise level map(그래서 총 8 channel)을 input으로 받고, RGB denoising의 경우에는 3 channel RGB image를 input으로 받게 된다.



### Experiments

__6.1. Real Image Datasets__

__DND__

 Camera를 이용하여 촬영한 dataset.

__SIDD__

 Smartphone을 이용하여 촬영한 dataset. sensor의 크기가 DSLR보다 작기 때문에 noise가 조금 더 심한 편이다.

__6.2. Implementation Details__

__Initial training of CycleISP__

 각 network마다 RRG를 몇 개 배치하였는지가 나온다. RGB2RAW와 RAW2RGB에서는 3개의 RRG에 각 RRG마다 5개의 DAB를, color correction network에서는 2개의 RRG에 각각 3개의 DAB module을 넣게 된다. 각 network을 학습 시킬 때에는 MIT-Adobe FiveK dataset을 이용했다.

__Fine-tuning CycleISP__

 Fine-tuning 과정에서는 joint fine-tuning을 진행한다. 그리고 synthetic realistic image dataset을 만드는데, 그 과정에서는 MIR flickr extended dataset을 만든다.

__Training denoising networks__

 denoising network는 4개의 RRG block마다 각각 8개의 DAB block을 가지고 있다.

__6.3. Results for RAW denoising__

![img12](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-12.PNG)

 결과는 위와 같다. 참고로, PSNR은 Peak signal to noise ratio, SSIM은 structural similarity index map으로, wikipedia를 참조하면 알 수 있다.(아마도 통신공학에서 자주 쓰이는 말이라 그 쪽 분야를 공부했다면 친숙한 단어일듯하다)

__6.4. Results for sRGB Denoising__

![img13](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-13.PNG)

 RGB denoising에 대한 결과는 위와 같다. visualization은 DND dataset 기준.

![img14](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-14.PNG)

 위 그림은 SIDD dataset이 기준이다.

__6.5. Generalization Test__

![img15](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-15.PNG)

 DND model에서 학습된 것을 SIDD로 보낸 것의 결과이다.

__6.6. Ablations__

![img16](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-16.PNG)

 RAW2RGB branch에서 각각 없앤 결과는 위와 같다. 무엇보다도 skip connection은 필수인 것을 확인할 수 있고, 그 어떤 것이라도 필요하다는 것을 확인할 수 있다.

 아래 Table에서는 DAB에서 CA와 SA를 series하게 연결한 경우와 parallel하게 연결한 것을 비교한 것이다. parallel한 이후 concat이 더 효과가 좋은 것을 볼 수 있다.

__6.7 Color Matching For Stereoscopic Cinema__

 몰랐는데 영화 같은 곳에서는 skilled technician을 아주 비싼값을 주고 데려와서 color matching을 시킨다고 한다. 그걸 cycleISP가 어느정도 해결해 줄 수 있다고 하는 것이다.

![img17](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210406-17.PNG)

 보면 별 차이가 없어보이는 것 같지만, 논문에서 직접 확인하여 엄청 확대해보면 색깔이 조금씩 다 다르다는 것을 확인할 수 있다.



### Conclusion



### Reference

Zamir, Syed Waqas, et al. "Cycleisp: Real image restoration via improved data synthesis." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 2020.