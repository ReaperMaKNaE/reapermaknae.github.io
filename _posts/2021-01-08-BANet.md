---
layout : post
title : "BANet"
date : 2021-01-08 +0900
description : Classical SfM 방법의 문제들을 BA layer로 해결한 것을 보여준, BANet, Dense Bundle Adjustment Networks, CVPR 2018 논문의 간단한 리뷰입니다.
tag : [PaperReview]
---

### BANet: Dense Bundle Adjustment Networks, CVPR 2018



### Abstract
SfM을 BA로 해결했음. 

tractable : 다루기 쉬운

### Introduction
 classic한 SfM 방식과 DNN 사이를 메꾸기 위해 BA를 적용시키고, damping factor를 예측하기 위해 LM Algorithm을 썼음.

geometric BA는 image의 모든 information을 exploit하지 않음

photometric BA는 moving objects, exposure, white balance changes에 대해 민감함.

white balance change : 색조 변경

여튼 가장 중요한건 우리가 만든 BA Layer는 back propagate이 가능함.

CodeSLAM이란 놈도 있음. 우린 back propagate이 가능한데 얘내들은 안된 점에서 차이가 있음.

그리고 이 친구들은 VAE(Variational Auto Encoder)를 썼음.(우린 standard encoder-decoder를 썼고)

이러한 점에서 우리는 backbone entwork를 사용할 수 있다는 점이 달랐음.

### Related Work
__Monocular Depth Estimation Networks__

monocular image에서 depth를 예측하는 건, 같은 이미지에서 수많은 다양한 가능성을 뽑아낼 수 있기 때문에 문제가 됨.

여튼 이러한 문제들은 ResNet을 활용한 사례나 CRF를 이용한 depth prediction에서 의미있는 결과를 뽑아냈음.

__Structure from Motion Networks__

최근 CNN들이 SfM의 문제들을 해결하기 위해 접목되고 있는 중.

가장 최근(2018년에 쓰여진 논문이라 논문 나올 당시인 2018년 기준으로)에는 LSTM RNN을 optimizer로 쓴
two-view SfM에서 nonlinear least squares를 해결하기 위해 제안된 것이 있음.

여튼 우리는 CNN feature에서 camera motion과 scene depth를 예측하기 위해 BA-Layer를 도입함.

여튼 이전 network들은 두 장의 image만을 input으로 받았는데, 우리가 이를 좀 개선했음.(hard-coded multi view geometry)

robustness를 향상시키기 위해 photometric error 대신 feature-metric error를 선택하였음.



### Bundle Adjustment Revisited
classic한 BA에 대해 간단한 소개.

given image에 대해서, 각 image에 대한 camera pose와 3d scene point coordinates가 있다면, reprojection error는 식 (1)과 같음.

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-1.png)

여기서 식(1)을 줄이는 방법(minimizing)으로 LM(Levenberg-Marquardt) algorithm이 적용됨.

![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-2.png)

이러한 typical한 geometric BA는 두가지 문제점이 있는데,

첫번째는 image information에서 feature types, image corners, blobs, line segments만이 활용 되었음.

두번째는 feature가 반드시 매칭이 되어야했음. RANSAC같은 outlier reproejction이 필요했지만, 이걸 써도 정확하진 않았음.

이러한 두 가지를 photometric BA Algorithm이 어느정도 해결했음.

근데 이 친구도 문제점이 있음.

첫번째는 photometric error가 non convexity를 증가시키기에 initailization에 상당히 민감하고,

두번째는 camera exposure, white balance와 같은 photometric 요소들에 민감해서 photometric calib.이 필요하며,

세번째는 moving objects와 같은 outlier들에 대해 민감했음.



### The BA-Net Architecture

위와 같은 문제점들을 우린 feature metric BA Algorithm을 제안하는 걸로 해결했음.

__Overview__

![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-3.png)

우린 여러장의 Image를 input으로 받고, DRN-54를 이용했음.

DRN54 이후 feature pyramid를 이용해서 BA Layer의 input을 만들어냄.

동시에 depth map generator가 depth map을 만들어내고, camera pose와 dense depth map이 equation 4에서 feature metric error를 줄여주는 process로 들어감.

__Feature Pyramid__

![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-4.png)

FPN을 BA-Layer에 적용시켰음. 기존 방식만 사용한 것에 비해, BA-Layer를 거친 feature map이 더 smooth한 것을 Figure 2에서 확인할 수 있음.

![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-5.png)

그리고 Figure 3에서는 feature distance map을 동일한 방법으로 더 smooth하다는 것을 확인할 수 있음.

__Bundle Adjustment Layer__

기존의 LM Algorithm은 아래 두 가지 이유로 differentiable 하지 않음.

첫번째는 일정 threshold를 넘어가면 iterative computation이 중단됨.

두번째는 각 반복에서 damping factor를 올리거나 내리는데, 이거 때문에 depth and motion parameter가 non differentiable함.

(이부분은 이해가 잘 안됨. if else 구문이 non differentiable한 것과 문제가 있나? back propagate이 아니라서 그런가?)

(대충 아래 문단을 보니 맞는 것 같다. 이러한 if-else로 인한 것들은 back-propagation을 불가능하게 만들고, feature learning이 안됨)

(이러한 구조를 non-differentiable하다고 하는 것 같음)

아무튼 첫번째 문제는 뭐 어느정도 해결이 됬는데, 두번째 문제는 아직 연구된 적이 없음.

이걸 우리는 differentiable LM algorithm으로 접근해봤음. if-else에 비해서, 같은 iteration내에 더 좋은 결과를 얻음.

![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210108-6.png)

모든 initialization은 0으로 초기화 되어 있음.

몇가지 식이 있는데, 생략.



__Basis Depth Maps Generation__

Parameter수가 엄청 많고, 다른 view에서 봤을 때에는 depth나 motion의 prediction 성능이 매우 poor하므로, 학습되는 양은 매우 적음.

이러한 문제를 standard encoder-decoder architectgure로 해결...?(DRN-54)

__Training__

__Camera Pose Loss__

rotation은 quaternion vector 차이의 norm을 이용했고, translation은 euclidean distance를 이용했음.

__Depth Map Loss__

berHu Loss를 적용했다는데.... 식은 안나와있다. 해당 논문을 참조해야할듯.

Zwald and S. Lambert-Lacroix. The berhu penalty and the grouped effect. CoRR, abs/1207.6868,2012

Laina, C. Rupprecht, V. Belagiannis, F. Tombari, and N. Navab. Deeper depth prediction with fully
convolutional residual networks. In International Conference on 3D Vision (3DV), pp. 239–248,
2016

### Evaluation


__Dataset__

ScanNet, KITTI를 사용했음.

__Comparisons with other methods__

ScanNet, KITTI의 경우에서 각 loss에 해당하는 차이를 비교.



### Conclusions and future works



### Appendix

Network Architecture Detail에 대한 내용, Evaluation time, Learned Features와 Pre-trained Features, 각종 optimization들에 대한 차이, DeMoN dataset에서의 evaluation 등...

View를 얼마나 적용하는가에 따른 에러의 차이, CodeSLAM과의 비교, Basis Depth Map의 visualization, 다른 방법들과의 비교등이 기록되어 있음.



### Reference

Tang, Chengzhou, and Ping Tan. "Ba-net: Dense bundle adjustment network." *arXiv preprint arXiv:1806.04807* (2018).

Zwald and S. Lambert-Lacroix. The berhu penalty and the grouped effect. CoRR, abs/1207.6868,2012

Laina, C. Rupprecht, V. Belagiannis, F. Tombari, and N. Navab. Deeper depth prediction with fully
convolutional residual networks. In International Conference on 3D Vision (3DV), pp. 239–248,
2016