---
layout : post
title : "COLMAP"
date : 2021-01-11 +1732
description : 한 대상을 촬영한 image bundle에서 3D reconstruction을 성공한 COLMAP이라 불리는 MVS를 주제로 한 Structure-from-Motion Revisited 논문의 간단한 리뷰입니다.
tag : [PaperReview]
---

### Structure-from-Motion Revisited, CVPR 2016



### Abstract

 순서가 제멋대로인 image들로부터 3D reconstruction을 이뤘음. 우린 여기서 robustness, accuracy, completeness 등등의 결과를 성공적으로 이끌어 낸 새로운 SfM technique을 propose함.



### Introduction

 순서가 뒤죽박죽인 image들에서 SfM을 이끌어내는 것은 지난 몇년동안의 과제였음. 뭐 여러 도전들이 있었지만, 분명하건대, 순서가 뒤죽박죽인 photo collection에서 recon을 이루는 것은 인기있는 분야임. 여태 robustness, accuracy, completeness, scalability는 여전히 key problem으로 나타나있었는데, 이를 해결한 새로운 SfM algorithm을 제공함. 모든 것은 오픈소스임.

[https://github.com/colmap/colmap](https://github.com/colmap/colmap)



### Review of Structure-from-Motion

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-15.PNG)

 SfM 은 서로 다른 viewpoint에서 찍힌 사진들을 가지고 3D structure를 recon하는 process를 말함. 보통 이러한 process는 feature extraction과 matching에서 시작해서 새로운 image를 register하고, scene point를 triangulating하고, outlier를 filter하고, BA로 recon을 refinement하는 과정이 있음.

__2.1 Correspondence Search__

 input image들 사이의 연관성을 살피는 것이 바로 first stage임.

__Feature Extraction__

 각각의 image에 대해서 SfM은 feature를 detect함. SIFT나 그의 변형 등이 자주 사용되었음.

__Matching__

 그 다음, SfM은 feature에서 같은 scene을 찾는 작업을 함. 보통은 overlap시켰을 때 얼마나 겹쳐지냐 등의 방법이었는데, 이러한 방법은 complexity가 엄청나고, 엄청나게 많은 image collection이 필요한 과정임. 물론 이러한 과정을 해결하려는 몇몇 접근들이 있었음.

__Geometric Verification__

 3단계는 overlapping된 image가 제대로 된 게 맞냐? 하는 검증단계임. 이러한 검증 단계에서는 projective geometry가 사용이 됨.(Homography를 이용해서 검증한단 말) 이러한 과정에서 Essential matrix라던지 Fundamental matrix가 사용이 되곤 했음. 근데 outlier들이 꽤나 있기 때문에, RANSAC같은 robust estimation이 필요함.

__2.2 Incremental Reconstruction__

__Initialization__

two-view reconstruction을 선택하게 되는데, 왜냐하면 얘내들이 처음에 초기화를 잘못시키면 recon은 더이상 좋아지지 않기 때문임. 

__Image Registration__

 two-view만으로는 완벽한 recon이 힘들기 때문에, PnP problem을 해결하기 위해서 새로운 image를 추가하게 됨. 2D-3D correspondence의 경우 outlier에 contaminate되어있기에, RANSAC과 같은 것들이 자주 사용됨.

__Triangulation__

 새롭게 들어온 image 친구들 역시 scene point를 observe해야하는 건 당연한 것. 이러한 과정에서 사용되는 것이 Triangulation임. 이 과정 역시 잘못되면 모델이 이상하게 recon이 되기 때문에, 이에 대한 연구도 많이 이루어졌음. 물론 우리도 이에 대한 연구를 section 4.3에 실었음.

__Bundle Adjustment__

 Image registration과 triangulation은 서로 다른 procedure이지만 매우 높은 상관관계를 지니고 있음. 하지만 이러한 과정에서 오류는 생길 수 밖에 없기 때문에, 이를 refine하는 BA(Bundle Adjustment)가 들어감. 이 BA의 원리는, reprojection error를 줄이는 방향으로 최적화시키는 알고리즘임.

![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-16.PNG)

 위 식에서 \pi는 projection을 말하고, \rho는 loss function을 말함. BA problem을 해결하기 위해 LM이 사용되기도 함. 이에 대한 자세한 내용은 아래 다크 프로그래머 님의 글 참조.

[https://darkpgmr.tistory.com/142](https://darkpgmr.tistory.com/142)

 여튼 우리는 section 4.5에서 조금 더 효과적인 BA 사용법을 propose할거임.



### Challenges

 이러한 SfM 과정 중에서도 모델이 잘못만들어지는 등의 문제점이 발생한다. 그러한 이유로는,

- 부적절한 scene graph로 인한 잘못된 correspondence에서 유발한 문제
- missing or inaccurate scene structure로 인한 image register 과정에서의 문제

등이 있다. 따라서 각 과정에서 정확도와 완성도를 최대로 하는 것은 SfM에서의 key challenge이다.



### Contributions

 여기에서는 우리가 SfM의 main challenge 항목들에 대해서 성능 향상을 일으킨 새로운 알고리즘들을 알려줄 것이다.

- Geometric Verification Strategy
- 새로운 Best View Selection
- Robust Triangulation
- Iterative BA
- 더 효과적인 BA parameterization

__4.1 Scene Graph Augmentation__

 (아래 내용에서 epsilon이 나오는데, 그냥 threshold같음. H는 homography, F는 fundamental, E는 essential, S는 similarity 등으로 두고 각 조합에 따라서 threshold를 준 것 같다.)

 우리가 제안하는 new geometric verification strategy는 multi-model임.

 먼저 fundamental matrix를 estimate함. 만약 N_F개의 inlier가 발견된다면, image pair에서 이걸 verify하는 방법은 다음과 같음. 같은 image pair에서 homography inliers(N_H)의 개수를 결정하여 transformation을 결정함. 만약 camera가 움직이는 scene인 경우, N_H/N_F < \epsilon_HF 이고, calibrated image의 경우에는 essential matrix를 estimate하고 ilier의 개수를 N_E라고 뒀음.

 만약 N_E/N_F > \epsilon_HF라면, calibration이 잘 됬다고 함. N_H/N_F < \epsilon_HF임에도 calibration이 잘 되었을 경우를 고려하여, essential matrix를 decompose하고 inlier의 연관성에서 point들을 triangulate하고, median triangulation 각도인 alpha_m을 결정함. 이 alpha_m을 이용해서 순수한 rotation(panoramic - 파노라마처럼 제자리에서 돌린 케이스인지)인지 planar scene(한 장면)인지를 구별할 수 있음. 

 인터넷에서 구할 수 있는 사진들의 가장 큰 문제점은 WTF임(일부러 이렇게 네이밍했나? watermarks, timestamps, frames의 약어임) image border에서 N_S inlier를 뽑아 그 유사도를 평가함. N_S/N_F > \epsilon_SF 이고 N_S/N_E > \epsilon_SE 를 만족하는 image pair인 경우 WTF로 고려되고 scene graph에 추가되지 않음.

 (위 과정이 의미하는 바는, watermark, timestamp, frame 같은 것들은 어떤 한 자리에 위치하게 되는데, 이러한 것들은 homography가 적용이 되지 않아도 같은 자리에 박혀있어서 similiarity를 올려주므로 이걸 기준으로 WTF set들을 제거한다는 의미)

 이러한 image들을 받았을 때 그 종류를 general, panoramic, planar로 구분하고, 여기서 non-panoramic은 제외하고 recon을 진행했음.

__4.2 Next Best View Selection__

 Next Best View selection을 사용하는 것에서는 triangulated point가 가장 많은 image를 선택하는 것이 인기있는 전략임. 근데 이걸 PnP로도 접근을 해서 해결한 사례도 있었음.

 next best view로는 아직 register 되지 않은 image들 중에서, triangulated point가 N개 이상인 경우를 후보로 넣음. 근데 인터넷에서 찍힌 사진들을 보면 알겠지만, 사실 거의 다 같은 각도에서 찍힌게 대부분임. 그래서 다른 사람들이 제안 했던 Exhaustive covariance propagation 등은 feasible하진 않음. 우린 여기서 효과적인 multi-resolution 분석을 이용했음.

 visible point와 그들의 분포를 유지하는 방향으로 후보자를 선택해야했음. 더 많은 visible point들과, 이 point들이 더욱 uniform distribution을 이룬다면 register 순서를 앞당기게 됨. 이를 해결하기 위해, 우리는 두 차원에서 image를 pixel-size grid로 이산화했음. 각 cell은 'empty' 혹은 'full' 상태로 나뉘게 되는데, empty cell들은 recon이 되면서 full state로 바뀌고, image의 score는 weight에 따라 높아지게 됨. 이러한 방식을 따라, 우린 visible point의 개수를 셀 수 있었음. 

![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-17.PNG)

 위 내용이 좀 ... 정리하면, 어떤 비슷하게 찍힌 사진 두 장에서 차이가 있다고 할 때, 이 차이를 보이는 점들의 분포가 일정하면 calibration이 굉장히 잘 된 case이므로, next best view selection을 하는 것에 좋은 것이 되고, 이 걸 어떻게 찾겠다 라는 방법이 적힌 것 같은데, 'visible point'라는 개념이 잘 안잡힌다. 아무튼 그러려니하고 넘어가보자.

__4.3 Robust and Efficient Triangulation__

 baseline이 작은 image pair를 잘 선택하는 것이 나중에 baseline이 큰 image 사이에서의 correspondence를 찾는 것에도 도움이 된다. 어찌됬던, 우리가 제안하는 효율적인, sampling based triangulation 방법은 outlier-contaminated된 feature에도 robust하게 point를 estimate할 수 있다.

 잘못된 feature track에서의 triangulation은 엄청 큰 에러를 수반함. 그래서 주의해야함.

 우린 outlier에 민감한 이런 triangulation 문제를 해결하기 위해 RANSAC을 도입하였음. 

 feature track T들을 뽑는데, 이 중에서 well-conditioned인 two-view triangulation을 최대로 하는 것이 우리의 목표임. 아래 식에서 x는 normalized image observation이고, P는 camera pose임.

![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-18.PNG)

 위에서 \tau는 DLT method를 의미함.(triangulation method 중 하나)

 여기서 well-conditioned를 찾는 방법은 두 가지임.

![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-19.PNG)

- 첫번째는 위 식을 만족해야 하고,

![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-20.PNG)

- 두번째는 위 두 식을 만족해야함.

View A와 View B에 대해서 한 점의 point를 d_A, d_B라 하면, d는 equation (4)를 통해 계산이 가능하고, model이 positive depth인 d_n을 가질 때 T_n을 고려하고, 그 reprojection error인 equation(5)의 결과는 threshold value인 t보다 작아야함. 근데 어느정도까지는 확실하게 outlier를 걸러내야 하기 때문에, RANSAC은 최소한 K번의 iteration을 돌아야함.

__4.4 Bundle Adjustment__

축적된 에러를 완화시키기 위해, 우리는 image registration과 triangulation 이후 BA를 적용시켰다. 보통 잘 적용을 안시키다보니, 우린 local하게 BA를 시킨 다음, global BA는 한번만 했다. 

__Parameterization__ 

 local BA에서 robust loss function은 cauchy function을 사용했다. 어떠한 image 조합에서도 camera model을 공유하는 Ceres Solver를 사용했고, 뒤죽박죽인 internet photo들을 위해 one radial distortion parameter와 함께인 simple camera model에 의존했다. (? 좀 이해가 어렵다. PCG solver를 썼다는데, 그 중에 Ceres solver가 들어있는듯)

__Filtering__

BA를 한 다음, 몇몇 observation의 경우 에러가 일어났을 수 있으니, 이러한 점들을 filter로 날려버림. mimimum triangulation angle을 넘어간 값들을 제끼는 것. 다음으로 global BA인데, 여기서는 인공적으로 사람들이 수정한(뽀샵질한) 사진들, panorama들에 의해 발생된 것들을 확인함. focal length라던가 distortion parameter들이 좀 중요하긴 한데, BA가 알아서 조정할 수 있도록 내버려 둘 계획임. 만약 large distortion을 가지거나 abnormal view field를 가지는 경우 BA가 알아서 제거하도록 했음.

__Re-Triangulation__

 VisualSfM과 유사한 방법으로, global BA 전에 re-triangulation을 실시함. BA가 camera parameter등을 잡아주는 역할을 잘 해내지만, post BA RT뿐 아니라 pre BA RT를 하기로 했음.(이거 좀 결과론적인 과정같은데, 결국 잘 되었다고 함.)

__Iterative Refinement__

 Bundler와 VisualSfM은 BA와 filtering을 한번만 했지만, 우린 여러번했음. 실험해보니 두 번만 해도 dramatic한 성능 향상을 보여주었음.

__4.5 Redundant View Mining__

 우리가 했던 방식은 Ni가 했던 방식이랑 유사한데, focus는 다음 세 가지임.

- 효과적인 camera grouping
- 한개의 submap에 많은 카메라를 담기 보다 scene을 매우 작게 분할하고 camera group을 겹침
- 각 변수 optimization을 생략해서 변화되는 부분을 제거할 수 있었음

  이러한 observation에 따라, unaffected scene part는 그룹으로 묶어버렸음.(쓸데없는게 많이 찍힌 부분) 이러한 부분을로 그룹을 만들고, reprojection error가 어느 이상이면 그 이미지들도 여기에다 넣었음.

 이렇게 추가된 이미지들은 쓰잘데기없으므로, 여기에서 발생하는 co-visible points들의 수는 mutual interaction의 단위로 설명이 됨.

 image i에서 해당 point가 visible하면 1, 아니면 0을 v_i에 저장하고, 이 때 상호 degree는 다음과 같음.

![img7](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-21.PNG)

 group을 만들기 위해 우리는 image를 좀 정렬했음.(해당 degree가 높은 순서대로)

 여기서 우린 V_ab가 maximum이 될 수 있도록 redundant group에서 이미지를 하나씩 뺐음.

 이 때 V_ab가 임의의 V를 넘고, redundant group의 절대값이(group의 절대값이라는 것도 잘 이해가 안간다. 개수를 말하는건가?) 임의의 값 S보다 작다면, image b를 추출해서 또 redundant group에다가 집어넣음. 



 여기까지 잠깐 정리를 하면, 3D recon이 update될 때, parameter들이 가장 최근에 update된 것에 영향을 받게 됨. 그래서 그 사이에 수많은 image들이 redundant(쓰잘데기없는) 것들로 분류가 되는데, 우린 이러한 그룹들을 한데 모아뒀음.(G_r 로) 근데 이런 이미지들은 서로 비슷한 visible point를 가지고 있을 거기 때문에, 얘내들을 한데 묶어두고 하나하나씩 빼다 보면 visible point가 많은 애들이 생기게 됨. 이 때 우리가 설정해놓은 V값이 있는데, 이 값보다 작아질 때 까지 사진을 계~~~속 뺄거임. 그러다보면 G_r에는 비슷해보이는 이미지들이 수두룩할것이고, 얘내들로 BA cost function을 짜면 camera parameter인 P를 찾을 수 있을것이라고 함. 

![img8](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-22.PNG)

 전체적인 코스트는 grouped와 ungrouped cost contribution들의 합이라고 함.(왜 이걸 더했는지는 또 잘 모르겠음)



### Experiments

__Next Best View Selection__

 각종 결과들이 실려있는데 여기선 생략. 대충 보면 mu(mean)와  sigma(std. dev)는 클수록 next view score에서 좋은 점수를 얻었음. 

![img9](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210111-23.PNG)

 그 외 다른 방법들과 비교한 것들도 실려있음.

__Robust and Efficient Triangulation__

__Redundant View Mining__

__System__



### Conclusion



### References

Schonberger, Johannes L., and Jan-Michael Frahm. "Structure-from-motion revisited." *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*. 2016.

COLMAP github, [https://github.com/colmap/colmap](https://github.com/colmap/colmap)

LM algorithm, 다크 프로그래머, [https://darkpgmr.tistory.com/142](https://darkpgmr.tistory.com/142)