---
layout : post
title : "DSAC++"
date : 2021-01-10 +1753
description : Camera Pose estimation에서 RANSAC의 개념을 도입해 성능 향상을 이루었던 DSAC을 조금 더 발전시킨 DSAC++을 다룬 Learning Less is More - 6D Camera Localization via 3D Surface Regression 논문의 간단한 리뷰입니다.
tag : [PaperReview]
---

### Learning Less is More - 6D Camera Localization via 3D Surface Regression, CVPR 2018



### Abstract

 우린 주어진 3D 환경에서 single RGB image로 카메라의 6D를 예측하는 task를 해결했음.

 

### Introduction

 거실에 가상 캐릭터를 집어넣는다던가, 뉴욕에서 자율주행차를 운전한다고 해보자. 여기서 다른 센서가 달린 장치를 쓴다고 하면, 사용했던 network를 그대로 사용하는 것엔 아무래도 무리가 있을 수 있다. 그에 반해 단순한 RGB camera는 low cost, rich output을 줄 수 있다. 그래서 우리는 단순한 RGB image만으로, 주어진 3D 환경에서 카메라의 위치를 estimation할 수 있는 방법을 소개한다.

 이전에 다른 방법들이 있었음. PoseNet이라던가, 아니면 이를 응용한 방법들이 있었지만, low localization accuracy를 보여주었음. 물론 이에 반해 다른 방법들도 있음. 우리가 최근에 발표했던 differentiable RANSAC의 경우, 다른 방법으로 접근해서 더 덜 복잡한(==간단한) task의 sequence로 camera pose estimation을 했음.

 조금 구체적으로, DSAC의 경우, 한 CNN이 장면의 coordinate를 예측하고, scene coordinates에서 랜덤하게 뽑힌 부분들이 camera pose를 예측한 가정을 하게 된다. 그럼 두 번째 CNN(scoring CNN)이 각 가정을 평가하고, 여기서 높은 점수를 받은 한개의 가정이 refine 되고 final camera pose estimation으로 설정된다.

 근데 우리는 이러한 모델의 단점 3가지를 발견했다.

- 두 번째 CNN인 scoring CNN이 overfit하는 경향이 있다는 점(error가 동일한 곳에서 발견되면 그 쪽으로 overfit되는 것을 말하는 듯)
- 해당 모델의 end-to-end training을 위한 initialization에, 어떤 경우에서는 사용하기 힘든 RGB-D data나 3D model이 필요하다는 점
- 높은 gradient variance를 가져서 불안정하다는 점

 그래서 우리는 조금 더 개선했음.

개선한 내용을 요약하면 아래와 같음.

- learnable component로만 이루어진 새로운 CNN을 소개
- local linearization을 통해, pose refinement가 효과적으로 differentiated한 것(end-to-end learning이  stable해 짐)
- GT Pose만으로 RGB image의 pose를 estimation
- 3D model을 쓰던 말던 상관없이 accuracy를 증가시킴.



### Related Work

  PoseNet, DSAC등의 이야기.



### Method

 우리의 pipeline은 이전에 우리가 진행했던 DSAC을 베이스로 두고 있음. 이건 2.1에서 다룰 예정.

 그리고 이후 key architecture나 training procedure를 설명할 예정임.

__2.1 Background__

DSAC의 경우, pose를 H라 하고 rotation을 \theta라 한다면, given RGB input __*I*__ 에 대해서 pose인 H를 estimate하는 것임.

__2.1.1 Scene Coordinate Regression__

CNN은 3D point에서 local coordinate frame에 속한 image pixel의 위치를 예측했음.

__2.1.2 Pose Hypothesis Sampling__

 PnP problem에 따르면, 4개의 scene coordinate이 있으면 camera의 pose를 unique하게 결정할 수 있음. 근데 이런 예측법은 에러가 있기 때문에, 우리는 PnP에서 n개의 가정을 두고, 각 가정은 learnable parameter w 에 dependent함.

__2.1.3 Hypothesis Selection__

 s(h) 함수는 각 hypothesis h에 대해서 점수를 매김.  여기서 가장 점수가 높은 친구가 결정이 됨. probability distribution을 따른다는데, 2.3에서 자세하게 설명할 예정.

__2.1.4 Hypothesis Refinement__

 Refinement R은 inlier pixel에 대해서 optimizing하고 조금 더 pose estimation을 잘 할 수 있도록 해주는 iterative procedure임. 자세한 내용은 2.4에서 다룰 예정.

__Learning the Pipeline__

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-14.PNG)

 probabilistic selection은 위 과정을 따름. learnable parameter를 optimizing하는 식은 위와 같고, 이걸 minimizing 하는 loss 값을 찾아 optimizing함.

 ![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-15.PNG)

 maximum value of rotational/translational error는 위와 같이 PDE에서 구할 수 있음. loss의 parameter에 대한 미분과 확률의 parameter에 대한 미분에 loss를 곱한 것은 우리가 back propagation할 수 있게 만들어 주었음.(여기서 E는 그냥 energy function을 의미하는 것 같음.  좀 쉽게 이해하기 위해서 PDE형식이 아니라고 봤을 때를 보면, loss가 작아짐에 따라 Energy function도 작아지는 것을 확인할 수 있다.(dw 항을 모두 제거해보자.))

__2.2 Scene Coordinate Regression__

 DSAC의 pipeline에서 CNN은 42x42 pixel image patch를 input으로 받고 center pixel에 대한 coordinate prediction을 output으로 내는데, 이런 디자인은 reusing computation없이는 neighboring patch들이 독립적으로 CNN에서 진행되기 때문이다.(뭔가 iteration calculation이 있어서 비효율적이다 라는 것을 말하는 듯) 우리는 DSAC에서 했던 것 처럼 VGG style architecture를 사용했음.

 ![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-16.PNG)

__2.3 Hypothesis Scoring__

 camera pose를 scoring하는 과정에서 DSAC은 분리된 CNN을 썼었음.

 The reprojection error는 다음과 같음.

 ![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-17.PNG)

 해당 식에서 i는 pixel, h는 hypothesis, C는 calibration matrix이다.

 final hypothesis는 다음 softmax distribution에 의해 결정된다.

 ![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-18.PNG)

  여기서 hyper-parameter인 alpha는 fixed value임. 이 값은 낮은 score를 기록한 hypothese의 영향을 제한하는 역할을 함.

 그런데 우리는 s(h)를 학습시키면서 두 가지 문제에 직면했음.

- Reprojection error가 global image structure에 대한 정보를 가지게 됨.(에러가 생기는 지점에서 overfitting이 일어난다는 뜻)
- 높은 점수를 받은 hypothesis가 들어오면, 그 쪽에 조금 더 weight가 실려버리도록 높은 점수를 주는 경향이 생김(음... 어찌보면 overfitting)

 regularization이 이걸 해결해 줄 수 있으나, 단순하고 differentiable한 inlier를 세는 것이 더 효과적이고 robust하는 것을 확인했다.

 ![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-19.PNG)

  위 그림이 그 오버피팅이 잘못된 예시인데, scoring CNN으로 estimation을 한 경우 pose가 좌측 방향으로 누적이되어 잘못된 결과를 유발한 것을 확인할 수 있고, 이를 DSAC++에서 새로 제안한 Soft Inlier Count를 사용해서 해결한 것을 그 우측에서 확인할 수 있다.

__Soft Inlier Counting__

 원래 RANSAC은 inlier를 따라서 모델을 세우는 것에 focus를 맞춘 형태이다. 우리의 적용 사례에서 inlier counting은 다음과 같다.

 ![img7](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-20.PNG)

 맨 앞의 1 비슷한 것은 Heaviside step function을 말하고, (위키피디아 참조. unit step function임: [https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9C%84_%EA%B3%84%EB%8B%A8_%ED%95%A8%EC%88%98](https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9C%84_%EA%B3%84%EB%8B%A8_%ED%95%A8%EC%88%98)) r_i는 reprojective error, \tau는 inlier threshold를 말한다.

 이를 응용해서 sigmoid function을 만들면 다음과 같다.

![img8](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-21.PNG)

 hyper parameter beta는 sigmoid의 softness를 결정하게 된다. 이러한 함수는 MSAC과 유사하나, 우리는 hard cut-off를 사용하진 않았다.(제한을 심하게 걸진 않았다는 뜻인 듯)

__Controlling Entropy__

 inlier score는 input의 난이도에 따라서 그 scale이 꽤나 컸다.(10^2~10^3) 이러한 크기는 end-to-end learning동안 smaller reprojection error를 만들었다. scale factor인 alpha를 결정하는 것은 굉장히 tedious하기에, 학습하면서 자동으로 적용되게 했다.

![img9](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-22.PNG)

 우린 shannon entropy를 측정하기로 했다. alpha를 optimize하는 방법으로 

![img10](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-23.PNG)

 위와 같은 식을 이용하였다. S star는 target entropy이다.

Shannon entropy: [https://en.wikipedia.org/wiki/Entropy_(information_theory)](https://en.wikipedia.org/wiki/Entropy_(information_theory))

 (보통 entropy가 낮은 쪽으로 세상이 흘러간다 라는 것을 어디서 들어서 여기에다 적용해보려고 하면, shannon entropy는 그게 1인 쪽으로 흘러간다는 것 같은데, 여기서 왜 저렇게 되는진 잘 모르겠다. 이해가 힘들다.)

__2.4 Training Procedure__

 학습을 시켜봤는데, local minimuim으로 빠지는 경우가 있었다. DSAC에서는 RGB-D 데이터로 학습을 해서 이걸 없앴는데, DSAC++에서는 3 step training schema를 써서 해결했다.

__Scene Coordinate Initialization__

 first training step에서는 DSAC에서 썼던 것과 유사한 방법으로 initialize를 시켰다.

![img11](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-24.PNG)

 star(*)는 GT를 의미하는데, 이게 GT로 쓸 3D scene model이 있으면 그냥 그대로 썼고, 만약 없다면 

![img12](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-25.PNG)

 위와 같이 전통적인 방법으로 GT를 만들어서 썼다.

__Optimization of Reprojection Error__

 두 번째로는 reprojection error를 optimize 했다.

![img13](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-26.PNG)

여기서 r_i는 equation 3에 해당하는 식.(reprojection error)

![img14](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-17.PNG)

 이러한 과정이 좀 과한거 아니냐 싶은데, accuracy를 잘 올려줬다.(3D model이 GT로 주어져있을 때에도)

__End-to-End Optimization__

 pose refinement는 현재의 pose estimate에 대해서 inlier pixel set을 결정하는 것 혹은 inlier set의 reprojection error에 대해서 pose를 optimizing하는 것 사이에서 왔다갔다 한다. 

 image set __*I*__ 안에 있는 inlier들에 대해서, reprojection error r_i가 \tau보다 작은 값들을 가지는 것들로 정의하고, 다음과 같은 reprojection error를 결정하게 되었다. pose는 argmin을 이용해서 추가적으로 optimize하고, iterative Gauss-Newton algorithm을 적용했다.  

![img15](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-27.PNG)

 iterative Gauss-Newton algorithm은 Multiple view geometry in computer vision 강의에서도 나오므로 해당 내용 참조. 

 DSAC에서는 연산요구량 때문에 inlier와 iteration을 제한했었는데, 이런 비슷한 행동을 하지 않기 위해 다음과 같은 방법을 적용했다.

 ![img16](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210110-28.PNG)

 refinement gradient(round R(h)/round w)가 대충 위 근처가 되면 optimization됬다 라고 치기로 했다. 덕분에 무한 iteration은 일어나지 않고 stable한 end-to-end training이 되었다.



### Experiments

 dataset으로는 7Scenes, 12Scenes, Cambridge Landmarks, Parameter Settings, Competitors를 썼다.

__3.1 Camera Localization Accuracy__

__3.2 Detailed Studies__

__Inlier Count vs Scoring CNN__

DSAC++와 DSAC으 ㅣ비교

__Impact of Training Steps__

__Stability of End-to-End Training__

__Varying Output Resolution__

__Scene Coordinate Initialization__

__Learning Scene Geometry__

__Run Time__



### Conclusion

Code는 아래 github에서 확인 가능.

[https://github.com/vislearn/LessMore](https://github.com/vislearn/LessMore)



### A. Parameter Listing

__A.1. Pipeline Parameters__

__A.2. Learning Parameters__



### References

Brachmann, Eric, and Carsten Rother. "Learning less is more-6d camera localization via 3d surface regression." *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*. 2018.

Heaviside step function, 위키피디아, [https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9C%84_%EA%B3%84%EB%8B%A8_%ED%95%A8%EC%88%98](https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%9C%84_%EA%B3%84%EB%8B%A8_%ED%95%A8%EC%88%98)

Shannon entropy, 위키피디아, [https://en.wikipedia.org/wiki/Entropy_(information_theory)](https://en.wikipedia.org/wiki/Entropy_(information_theory))

DSAC++ github, [https://github.com/vislearn/LessMore](https://github.com/vislearn/LessMore)