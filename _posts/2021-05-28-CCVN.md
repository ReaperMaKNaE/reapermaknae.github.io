---
layout : post
title : "CCVN"
date : 2021-05-28 +0900
description : Conditional cost volume normalization을 적용하여 depth completion task에서 우수한 성능을 보여준 CCVN을 소개한 논문의 리뷰입니다.
tag : [PaperReview]
---

### 3D LiDAR and Stereo Fusion using Stereo Matching Network with Conditional Cost Volume Normalization, 



### Abstract

 active하고 passive한 depth sensing technique이 LiDAR sensor와 stereo camera에 영감을 주어 depth perception을 향상시키고 있다. depth를 LiDAR와 stereo modality에 직접적으로 융합하는 반면, 우리는 stereo matching network의 2가지 장점을 취했다.

- Input Fusion
- Conditional Cost Volume Normalization

 이번에 제안한 framework은 현재 stereo matching neural network에서 자주 사용되는 cost volume과 큰 연관이 있다. 우리는 실험적으로 우리의 방법이 KITTI stereo와 depth completion dataset에서 유효하다는 것을 증명하였다. 더욱이, 우리는 CCVN의 hierarchical extension 과 함께 제안한 방식이 model size, computation time의 관점에서 stereo matching network들을 이기는 것을 확인할 수 있다.



### Introduction



 정확한 3D perception은 여러 로보틱스 및 컴퓨터비전에서 다양한 역할을 하고 있어 중요하게 다루어진다. 다양한 테크닉들이 depth estimation을 하기 위해 제안되었는데, 이에는 RGB-D camera, 3D LiDAR scanner, stereo camera등이 사용되고 있다. 우리는 이러한 sensor들이 각각 장단점을 가지고 있어서 그 어떤 환경에서도 완벽한 performance를 낼 수 없다는 것을 관찰하게 되었다. 예를 들자면, RGB-D Sensor는 short range에서만 유효하고, 3D LiDAR가 outdoor environment에서 도전적인 대체재로 떠오르고 있다. 하지만, 3D LiDAR는 그 값이 너무 비싸고 오로지 sparse한 3D depth estimate를 할 수 밖에 없다. 대조적으로, stereo camera는 stereo matching algorithm을 기반으로 dense한 depth map을 얻을 수 있지만 반복적인 패턴이 존재하는 곳이나 homogeneous appearance, 혹은 illumination의 변화가 큰 곳에서는 사용이 불가능하다는 단점이 있다.

 이런 서로 다른 센서들을 서로 상호보완해주기 위해, 몇몇 work들은 어떻게 여러개의 모달리티를 합칠 수 있는지에 대해 연구했다(depth estimation 관점에서). 이번 논문에서는 우리는 passive stereo camera와 active 3D LiDAR 센서를 고려했다(자주 사용되는 인기 품목). 현재 존재하는 work들은 3D LiDAR에서 오는 sparse measurement와 stereo matching에서 오는 dense depth의 combination에 대해 주로 연구하고 있다. 하지만, 풍부한 stereo image에서 제공되는 풍부한 information이 fusion에서는 잘 이용이 되고 있지 않다. 이러한 문제를 해결하기 위해, 우리는 3D LiDAR information을 stereo matching method에 융합하기 위한 연구를 제안한다.

![img1](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-1.PNG)

 우리가 이러한 방향으로 연구하는 동기는 typical stereo matching algorithm이 stereo pair에서 애매모호한 pixel correspondence에서 좋은 성능을 내지 못하고 있다는 것을 관찰하였기 때문이다. 그래서 3D LiDAR depth point가 matching의 search space와 애매모호함을 줄일 수 있는 것을 도와줄 수 있는지 가능하도록 하는 것이다.

 3D LiDAR sensor에서 오는 depth point가 매우 sparse하기 때문에, stereo pair를 이용해서 얻은 pixel location으로 바로 연결하는 것은 간단한 작업이 아니다. 대신에, 우리는 sprase poiint를 이용하여 higher-level feature representation을 정규화하는 것에 focus를 했다. 최근 SOTA deep model은 두 가지 component로 구성이 되어 있다. matching cost computation과 cost volume regularization이다. 전자의 경우 image patch의 deep representation을 추출하는 것이고, 후자의 경우에는 마지막 depth estimate를 예측하기 위해 stereo image를 통해 얻은 potential match를 모두 정규화 한 이후 aggregate 하기 위해 search space를 만드는 것이다.

 이러한 두 가지 component를 융합해서, 우리는 2가지 테크닉으로 stereo matching network을 확장할 것이다.

- Joint feature representation을 만들기 위해 RGB image와 sparse LiDAR depth에서 오는 geometric information을 융합하기 위한 __input Fusion__
- LiDAR measurement에 의존하는 cost volume optimization을 정규화할 수 있는 __Conditional Cost volume normalization(CCVNorm)__

 우리가 생각한 기술이 평범하게 사용되는 cost volume component에 의존하는 것이 아닌, 다른 모델과의 유연성을 가지게 된다. 실험은 KITTI Stereo 2015 dataset과 KITTI Depth Completion dataset에서 수행되었다. 추가적으로, 우리는 서로 다른 variant를 ablation study를 통해 알아보았다. 최종적으로, 우리는 sparse sensory input을 추가한 fusion이 더 좋은 성능을 보여준다는 것을 확인할 수 있었다.



### Related Works

__Stereo Matching.__

__RGB Imagery and LiDAR Fusion.__

__Conditional Batch Normalization.__



### Method

 위와 같은 과정에 의해 영감을 받아, 우리는 3D LiDAR data를 stereo matching network에 융합하기 위해 두 가지 기술을 제안한다.

- input fusion
- CCVNorm

 앞으로 우리는 baseline stereo matching network를 설명하고 다음으로 우리의 방법에 대해 자세히 설명할 것이다. 마지막으로, CCVNorm의 hierarchical extension을 소개한다. 우리가 소개하는 방법은 아래 그림에 나타나있다.

![img2](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-2.PNG)

 __A. Preliminaries of Stereo Matching Network__

 우리의 방법에서 사용한 end-to-end differentiable stereo matching network를 Figure 2와 같이 사용했다. GC-Net을 기반으로 모델을 설계하였고, typical stereo matching algorithm의 파이프라인을 갖춘 4 가지 중요한 요소로 구성이 되어 있다.

 첫번째는 stereo matching의 cost를 계산하기 위해 rectified left-right stereo pair에서 deep feature을 뽑아낸다. encoded context information의 representation은 simple photometric appearance 보다 더욱 견고한 similarity measurement를 측정하여 stereo image를 통한 pixel match의 예측에 도움이 되도록 한다. cost volume은 left-image와 right-image에서 뽑힌, 각 disparity level에서 추출된 deep features를 융합하는 것으로 만들어진다. 자세한 설명으로, cost volume은 실제로 stereo image의 potential match를 모두 포함하고 있어 matching의 search space로 작동하게 된다. 이후, 일련의 3D convolutional operation이 cost volume regularization에 적용이 되고, final disparity estimation은 output volume에 대해서 regression을 수행하게 된다.

__B. Input Fusion__

 stereo matching network의 cost computation stage에서 좌/우측 stereo pair는 convolution layer를 지나서 feature를 뽑게 된다. RGB image와 LiDAR data에서 각각 appearance와 geometry information을 얻기 위해 우리는 stereo image를 단순히 sparse LiDAR depth map에 fusion한 input fusion을 제안한다. 이는 다른 논문에서도 비슷하게 소개가 되었는데, 우리는 LiDAR depth map을 각 image에 맞게 sweep해서 썼다는 것이 차이점에 있다.(disparity를 분석해서 warping한 것을 말하는 듯)

__C. Conditional Cost Volume Normalization(CCVNorm)__

 input fusion에 더하여, 우리는 sparse LiDAR depth point들을 stereo matching network의 cost regularization step으로 융합하는 것을 제안한다.(이는 matching의 search space를 줄이고 애매모호한 것들을 개선한다.) Conditional Batch Normalization에 영감을 받아, 우리는 CCVNorm(Conditional Cost Volume Normalization)을 제안한다. 주어진 N개의 example로 구성된 mini batch $\mathcal{B}$ 에 대해서, 3D Batch Normalizatoin은 다음과 같다.

![img3](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-3.PNG)

 위 식에서 $\epsilon$ 은 numerical stability를 의미하는 작은 상수이며, $\gamma, \beta$ 는 learnable BN parameter이다. 이들이 conditional batch normalization으로 넘어가게 되면, learnable BN parameter는 conditional information인, LiDAR data에 의존하는 cost volume의 feature map을 조정하는 $L$ 의 함수로 다음과 같이 변경된다.

![img4](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-4.PNG)

하지만, 바로 typical CBN을 3D CNN으로 적용시키는 것은 몇몇 consideration때문에 문제가 된다.

- 이전과는 다르게 conditional input이 sparse map임
- sparse map의 빈 공간을 커버칠 수 있는 대체 전략이 필요
- 서로 다른 disparity level에서 valid value들은 서로 다른 contribution을 가지고 있어야함

 이를 해결할 방법으로 우리는 CCVNorm을 제안한다.

![img5](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-5.PNG)

 여기서 우리가 3D LiDAR에 적용하기 위한 식은 아래와 같다.

![img6](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-6.PNG)

 직관적으로, 주어진 LiDAR point에 대해, disparity level d의 cost volume에서 corresponding pixel의 representation은 depth value가 d에 consistent하면 conditional modulation을 통해 좋아지는 것이고, inconsistent하면 suppressed 되는 것이다. 대조적으로, invalid value와 함께 이러한 LiDAR point들을 위해, cost volume의 regularization은 unconditional batch normalization version으로 퇴화한다. 우리는 다음과 같은 두 다른 선택지를 통해 function을 만들었다.

__Categorical CCVNorm:__ D entry의 look up table이 LiDAR value를 normalization parameter로 map이 되도록 만들어졌다.

__Continuous CCVNorm:__ sparse LiDAR data와 normalization parameter 사이의 continuous mapping을 설계하기 위해 만들어진 CNN이다. 우리의 실험에서 우리는 ResNet34의 첫번째 block을 LiDAR data를 encode하는 것에 사용하였다.

__D. Hierarchical Extension__

 우리는 categorical, continuous CCVNorm 두 가지가 많은 수의 parameter를 관찰하는 것을 알 수 있었다. 각 normalization layer에 대해서 categorical version이 만족할만한 performance를 뽑아내려면 꽤나 많은 양의 parameter를 필요로 한다. model size를 줄이기 위해, 우리는 hierarchical extension인, __HierCCVNorm__ 을 제안한다. 여기서 normalization parameter는 다음과 같다.

![img7](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-7.PNG)

 기본적으로, LiDAR disparity를 Categorical CCVNorm에 mapping하는 과정은 일련의 두 스텝으로 정리가 된다. 대충 다른 lookup table에서 온 haperparameter들을 이용해서 조정한다는 내용.



### Experimental Results

 두 KITTI dataset에서 우리가 제안한 방법을 평가해보았다.

__A. Experimental Settings__

__KITTI Stereo 2015 Dataset.__

![img8](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-8.PNG)

__B. Evaluation on the KITTI Dataset.__

![img9](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-9.PNG)

__C. Ablation Study__

__Overall Results__

![img10](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-10.PNG)

__Categorical vs continuous.__

__Benefits of Hierarchical CCVNorm.__

__D. Robustness to LiDAR Density__

__E. Discussions__

__Sensitivity to Sensory Inputs.__

__Qualitative Results.__

![img11](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-11.PNG)

__F. Computational Time__

![img12](https://raw.githubusercontent.com/ReaperMaKNaE/reapermaknae.github.io/main/assets/img/20210528-12.PNG)



### Conclusion



### Reference

Wang, Tsun-Hsuan, et al. "3d lidar and stereo fusion using stereo matching network with conditional cost volume normalization." *arXiv preprint arXiv:1904.02917* (2019).

